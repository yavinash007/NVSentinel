# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

replicaCount: 1

image:
  repository: ghcr.io/nvidia/nvsentinel/preflight
  pullPolicy: IfNotPresent
  tag: latest

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 65532
  runAsGroup: 65532
  capabilities:
    drop: ["ALL"]

service:
  type: ClusterIP
  port: 443
  targetPort: 8443

resources:
  requests:
    cpu: 250m
    memory: 512Mi
  limits:
    cpu: 500m
    memory: 1024Mi

livenessProbe:
  httpGet:
    scheme: HTTPS
    path: /healthz
    port: 8443
  initialDelaySeconds: 5
  periodSeconds: 10

readinessProbe:
  httpGet:
    scheme: HTTPS
    path: /healthz
    port: 8443
  initialDelaySeconds: 2
  periodSeconds: 5

nodeSelector: {}
tolerations: []
affinity: {}

webhook:
  port: 8443
  failurePolicy: Fail
  timeoutSeconds: 10
  # Set to true to create the two-tier CA
  # Set to false to use an existing CA issuer
  createIssuer: true
  # Only used when createIssuer=false
  certIssuer: ""
  caCertificateName: ""

# Local fallback values - global.dcgm takes precedence when set
dcgm:
  service:
    # DCGM hostengine service endpoint (fallback when global.dcgm.service not set)
    endpoint: "nvidia-dcgm.gpu-operator.svc"
    port: 5555
  # Diagnostic level:
  #   1 = Quick (~30 seconds) - basic health check
  #   2 = Medium (~2 minutes) - more thorough
  #   3 = Long (~15 minutes) - comprehensive
  diagLevel: 2
  # Event processing strategy: EXECUTE_REMEDIATION or STORE_ONLY
  processingStrategy: "EXECUTE_REMEDIATION"

initContainers:
  - name: preflight-dcgm-diag
    image: ghcr.io/nvidia/nvsentinel/preflight-dcgm-diag:latest
    volumeMounts:
      - name: nvsentinel-socket
        mountPath: /var/run
    # Full corev1.Container fields supported:
    # resources:
    #   limits:
    #     memory: 512Mi

  # NCCL loopback test - validates intra-node GPU-to-GPU communication (NVLink/PCIe)
  - name: preflight-nccl-loopback
    image: ghcr.io/nvidia/nvsentinel/preflight-nccl-loopback:latest
    env:
      - name: BW_THRESHOLD_GBPS
      # Minimum acceptable bus bandwidth
      # Valid for NVLink GPU-to-GPU interconnect
      # If using PCIe GPU-interconnect, this threshold should be set to ~15 GB/s
        value: "150"  # Minimum acceptable bus bandwidth in GB/s
      - name: TEST_SIZE_MB
        value: "256"  # Message size for all-reduce test
      # To skip the bandwidth check, set SKIP_BANDWIDTH_CHECK to true
      # By default, the bandwidth check is enabled
      # Checks if the loopback test passes without checking the bandwidth
      # - name: SKIP_BANDWIDTH_CHECK
      #   value: "true" 
    volumeMounts:
      - name: nvsentinel-socket
        mountPath: /var/run

gpuResourceNames:
  - "nvidia.com/gpu"

# Network resource names to copy to init containers (RDMA, InfiniBand, etc.)
networkResourceNames:
  - "nvidia.com/mlnxnics"

# Label-based namespace selection
# Enable preflight in a namespace: kubectl label namespace <name> nvsentinel.nvidia.com/preflight=enabled
namespaceSelector:
  matchLabels:
    nvsentinel.nvidia.com/preflight: "enabled"

networkPolicy:
  enabled: true
